[output.log]
# DON'T CHANGE
Succeed_Response = Succeed Response:\s+(\d+)
Duration = Duration:\s+([\d.]+)s
Input_Tokens = Input Tokens:\s+(\d+)
Onput_Tokens = Output Tokens:\s+(\d+)
RPS = RPS:\s+([\d.]+)
Input_Tokens_per_Second = Input Tokens per Second:\s+([\d.]+)
Output_Tokens_per_Second = Output Tokens per Second:\s+([\d.]+)
End_to_End_latency_P50 = End to End latency\(ms\),\s+P50:\s+([\d.]+)
End_to_End_latency_P90 = End to End latency\(ms\),\s+P50:[\s\d.,]+P90:\s+([\d.]+)
End_to_End_latency_P99 = End to End latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+([\d.]+)
End_to_End_latency_Avg = End to End latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+[\s\d.,]+Avg:\s+([\d.]+)
First_token_latency_P50 = First token latency\(ms\),\s+P50:\s+([\d.]+)
First_token_latency_P90 = First token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+([\d.]+)
First_token_latency_P99 = First token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+([\d.]+)
First_token_latency_Avg = First token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+[\s\d.,]+Avg:\s+([\d.]+)
Next_token_latency_P50 = Next token latency\(ms\),\s+P50:\s+([\d.]+)
Next_token_latency_P90 = Next token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+([\d.]+)
Next_token_latency_P99 = Next token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+([\d.]+)
Next_token_latency_Avg = Next token latency\(ms\),\s+P50:[\s\d.,]+P90:\s+[\s\d.,]+P99:\s+[\s\d.,]+Avg:\s+([\d.]+)
Average_token_latency = Average token latency\(ms\)\s+:\s+([\d.]+)
locust_num_requests = \"num_requests\":\s+(\d+)
locust_num_failures = \"num_failures\":\s+(\d+)

[stats.csv]
# DON'T CHANGE
columns_name = 50%, 99%
row_name = Aggregated

[testspec.yaml]
benchmarkresult = *
benchmarkspec = users max_requests
hardwarespec = containerRuntimeVersion cpu