bigcode-eval@git+https://github.com/bigcode-project/bigcode-evaluation-harness.git@e5c2f31625223431d7987f43b70b75b9d26ba118
evaluate
jieba
langchain_community
langchain_huggingface
lm-eval==0.4.3
ragas
rouge_score
